{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb_sentiment_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wYkFCTx57Flz",
        "colab_type": "code",
        "outputId": "e91dc704-d299-4905-d1cd-ce85732dda62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import GloVe\n",
        "import os\n",
        "import glob\n",
        "import io\n",
        "import random\n",
        "SEED = 2206\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9994c830f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "qBaaM8Wq7Fmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6a795a09-9e44-487b-bdc0-7adba07e2e31"
      },
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en')\n",
        "'''\n",
        "\n",
        "# Clean text before feeding it to spaCy\n",
        "punctuations = string.punctuation\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "# Define function to cleanup text by removing personal pronouns, stopwords, and punctuation\n",
        "def cleanup_text(docs, logging=False):\n",
        "    texts = []\n",
        "    counter = 1\n",
        "    for doc in docs:\n",
        "        if counter % 1000 == 0 and logging:\n",
        "            print(\"Processed %d out of %d documents.\" % (counter, len(docs)))\n",
        "        counter += 1\n",
        "        doc = nlp(doc, disable=['parser','ner'])\n",
        "        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n",
        "        tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n",
        "        tokens = ' '.join(tokens)\n",
        "        texts.append(tokens)\n",
        "    return pd.Series(texts)\n",
        "\n",
        "def remove_s(text):\n",
        "    word_clean=List[Any]=[word for word in text if word != '\\s']\n",
        "    return word_clean\n",
        "# Parse documents during words into vectors\n",
        "def parse_documents(cleaned_text):\n",
        "    print('Parsing documents...')\n",
        "    train_vec = []\n",
        "    for doc in nlp.pipe(cleaned_text, batch_size=500):\n",
        "        if doc.has_vector:\n",
        "            train_vec.append(doc.vector)\n",
        "            #print(len(doc.vector))\n",
        "        # If doc doesn't have a vector, then fill it with zeros.\n",
        "        else:\n",
        "            train_vec.append(np.zeros((300,), dtype=\"float32\"))\n",
        "    train_vec = np.array(train_vec)\n",
        "    #print(len(train_vec))\n",
        "    #sys.exit(1)\n",
        "    return train_vec\n",
        "'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# Clean text before feeding it to spaCy\\npunctuations = string.punctuation\\nstopwords = stopwords.words(\\'english\\')\\n\\n# Define function to cleanup text by removing personal pronouns, stopwords, and punctuation\\ndef cleanup_text(docs, logging=False):\\n    texts = []\\n    counter = 1\\n    for doc in docs:\\n        if counter % 1000 == 0 and logging:\\n            print(\"Processed %d out of %d documents.\" % (counter, len(docs)))\\n        counter += 1\\n        doc = nlp(doc, disable=[\\'parser\\',\\'ner\\'])\\n        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != \\'-PRON-\\']\\n        tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\\n        tokens = \\' \\'.join(tokens)\\n        texts.append(tokens)\\n    return pd.Series(texts)\\n\\ndef remove_s(text):\\n    word_clean=List[Any]=[word for word in text if word != \\'\\\\s\\']\\n    return word_clean\\n# Parse documents during words into vectors\\ndef parse_documents(cleaned_text):\\n    print(\\'Parsing documents...\\')\\n    train_vec = []\\n    for doc in nlp.pipe(cleaned_text, batch_size=500):\\n        if doc.has_vector:\\n            train_vec.append(doc.vector)\\n            #print(len(doc.vector))\\n        # If doc doesn\\'t have a vector, then fill it with zeros.\\n        else:\\n            train_vec.append(np.zeros((300,), dtype=\"float32\"))\\n    train_vec = np.array(train_vec)\\n    #print(len(train_vec))\\n    #sys.exit(1)\\n    return train_vec\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "h5Xd-Rp67Fnc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ff09a70c-ccc5-4b83-9bec-c6caa83c1488"
      },
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(lower = True, include_lengths = True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential = False)\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:04<00:00, 20.9MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rZim_iJvbo11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "4373f525-abbf-489c-af9a-4a8a41512bd9"
      },
      "cell_type": "code",
      "source": [
        "print('train_data.fields', train_data.fields)\n",
        "print('len(train_data)', len(train_data))\n",
        "print('vars(train_data)', vars(train_data[0]))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data.fields {'text': <torchtext.data.field.Field object at 0x7f9991c93fd0>, 'label': <torchtext.data.field.LabelField object at 0x7f9991c93588>}\n",
            "len(train_data) 25000\n",
            "vars(train_data) {'text': ['an', \"insomniac's\", 'nightmare', 'is', 'the', 'story', 'of', 'a', \"man's\", 'plunge', 'into', 'insanity.', 'having', 'chronic', 'insomnia,', 'jack', 'is', 'plagued', 'by', 'hallucinations;', 'causing', 'him', 'to', 'try', 'and', 'determine', 'what', 'is', 'real', 'and', 'what', \"isn't.<br\", '/><br', '/>we', 'find', 'out', 'interesting', 'things', 'about', 'jack', 'near', 'the', 'end,', 'and', 'think', 'that', 'by', 'the', 'time', 'the', 'movie', 'is', 'over', 'we', 'will', 'have', 'a', '\"happily', 'ever', 'after\"', 'hollywood', 'ending.', 'wrong.', 'this', 'is', 'new', 'york', 'city,', 'the', 'place', 'where', 'nobody', 'sleeps.<br', '/><br', '/>tess', 'nanavati', '(writer', 'and', 'director)', 'has', 'herself', 'a', 'good', 'film', 'in', \"'an\", \"insomniac's\", \"nightmare'.\", 'a', 'talented', 'filmmaker', 'and', 'writer', '(she', 'made', 'this', 'film', 'right', 'after', 'her', 'high', 'school', 'graduation),', 'she', 'has', 'real', 'potential', 'and', 'will', 'be', 'one', 'to', 'watch', 'in', 'the', 'upcoming', 'future.<br', '/><br', '/>as', 'i', 'watched', 'this', 'short', 'film', 'i', 'was', 'constantly', 'uncomfortable;', 'between', 'the', 'music,', 'bleak', 'scenery,', 'and', 'realistic', 'portrayal', 'of', 'an', 'insomniac', 'by', 'dominic', 'monaghan', '(as', 'jack),', 'i', 'desperately', 'wanted', 'to', 'turn', 'this', 'off', 'at', 'times', 'just', 'to', 'escape', 'from', 'it.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jxjBZwbE7Fn7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data, validation_data = train_data.split(random_state=random.seed(SEED), split_ratio=.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JLolXyYmbmC3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tZLjsgh47FoK",
        "colab_type": "code",
        "outputId": "e41d9e6f-dd8f-4d3b-fb57-4cff176a9a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')\n",
        "print(f'Number of validation examples: {len(validation_data)}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 16000\n",
            "Number of testing examples: 25000\n",
            "Number of validation examples: 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MtC3PDoa7Fou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ca3c7541-0404-4adc-95c2-28d0bab129e5"
      },
      "cell_type": "code",
      "source": [
        "# Building Vocab\n",
        "TEXT.build_vocab(train_data, vectors =  GloVe(name = '6B', dim =  300), max_size=25000)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [01:55, 7.46MB/s]                           \n",
            "100%|█████████▉| 399316/400000 [00:48<00:00, 8382.73it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XmSlUO2a7FpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "637cbd77-3266-4daf-c407-831037ae955b"
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 3\n",
        "\n",
        "device = 'cuda:0'\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, validation_data, test_data), \n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)\n",
        "\n",
        "batch = next(iter(train_iterator))\n",
        "print(batch.text)\n",
        "print(batch.label)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[ 4439,     2,   117,  ...,    11,   313, 15926],\n",
            "        [  102,    66,    10,  ...,     1,     1,     1],\n",
            "        [   10,    20,    14,  ...,     1,     1,     1]], device='cuda:0'), tensor([473,  81,  37], device='cuda:0'))\n",
            "tensor([0, 1, 1], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R4QJKlmd7Fpf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        #self.relu1 = nn.ReLU()\n",
        "        \n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        # output = [sent len, batch size, hid dim]\n",
        "        # hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        hidden2 = self.fc1(hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc2(hidden2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pqj-rdWt7Fqa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 300\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "# accuracy function\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, \n",
        "    this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc\n",
        "\n",
        "# train function\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "# evaluate accuracy\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yGIfPwWd7Fqr",
        "colab_type": "code",
        "outputId": "ca5d7407-263c-4706-bce3-c22cccc75599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        }
      },
      "cell_type": "code",
      "source": [
        "# train model\n",
        "N_EPOCHS = 1\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | \\\n",
        "          Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | \\\n",
        "          Val. Acc: {valid_acc*100:.2f}% |')\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-ed2fb117ebfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2930e1d4233f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-c0ea24fa3261>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# embedded = [sent len, batch size, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# output = [sent len, batch size, hid dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "EqNKzfYV7FrA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}